{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d3abea7",
   "metadata": {},
   "source": [
    "# Minetester PPO Interpretabilty Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4197a960",
   "metadata": {},
   "source": [
    "## Policy and Image Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3e3ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Paths\n",
    "SAVED_MODEL_PATH = \"ppo_treechop-v0.model\"\n",
    "\n",
    "IMAGE_FOLDER = \"screenshots/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a79c56",
   "metadata": {},
   "source": [
    "## Load model, define utility functions, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58da472e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dependencies\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import jax\n",
    "import flax\n",
    "import flax.linen as nn\n",
    "import jax.numpy as jnp\n",
    "import gym\n",
    "import cv2\n",
    "\n",
    "from typing import Sequence, Callable\n",
    "from flax.linen.initializers import constant, orthogonal\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c329ef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Neural Networks\n",
    "\n",
    "class Network(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x, l1_inp=False,l2_inp=False,l3_inp=False,inp=None):\n",
    "        l1, l2, l3 =None, None, None\n",
    "        \n",
    "        if not (l1_inp or l2_inp or l3_inp):\n",
    "            x = jnp.transpose(x, (0, 2, 3, 1))\n",
    "            x = x / (255.0)\n",
    "            x = nn.Conv(\n",
    "                32,\n",
    "                kernel_size=(8, 8),\n",
    "                strides=(4, 4),\n",
    "                padding=\"VALID\",\n",
    "                kernel_init=orthogonal(np.sqrt(2)),\n",
    "                bias_init=constant(0.0),\n",
    "            )(x)\n",
    "            l1 = x\n",
    "        if l1_inp:\n",
    "            x = inp\n",
    "        if not (l2_inp or l3_inp):\n",
    "            x = nn.relu(x)\n",
    "            x = nn.Conv(\n",
    "                64,\n",
    "                kernel_size=(4, 4),\n",
    "                strides=(2, 2),\n",
    "                padding=\"VALID\",\n",
    "                kernel_init=orthogonal(np.sqrt(2)),\n",
    "                bias_init=constant(0.0),\n",
    "            )(x)\n",
    "            l2 = x\n",
    "        if l2_inp:\n",
    "            x = inp\n",
    "        if not (l3_inp):\n",
    "            x = nn.relu(x)\n",
    "            x = nn.Conv(\n",
    "                64,\n",
    "                kernel_size=(3, 3),\n",
    "                strides=(1, 1),\n",
    "                padding=\"VALID\",\n",
    "                kernel_init=orthogonal(np.sqrt(2)),\n",
    "                bias_init=constant(0.0),\n",
    "            )(x)\n",
    "            l3 = x\n",
    "        if l3_inp:\n",
    "            x = inp\n",
    "        x = nn.relu(x)\n",
    "        x = x.reshape((x.shape[0], -1))\n",
    "        x = nn.Dense(512, kernel_init=orthogonal(np.sqrt(2)), bias_init=constant(0.0))(x)\n",
    "        x = nn.relu(x)\n",
    "        return x, (l1,l2,l3)\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        return nn.Dense(1, kernel_init=orthogonal(1), bias_init=constant(0.0))(x)\n",
    "\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    action_dim: Sequence[int]\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        return nn.Dense(self.action_dim, kernel_init=orthogonal(0.01), bias_init=constant(0.0))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b79880e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(models, model_path):\n",
    "    network, actor, critic = models\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        data = f.read()\n",
    "\n",
    "    target = [\n",
    "        {},\n",
    "        [\n",
    "            network.params,\n",
    "            actor.params,\n",
    "            critic.params,\n",
    "        ],\n",
    "    ]\n",
    "\n",
    "    deserialized_data = flax.serialization.from_bytes(target, data)\n",
    "\n",
    "    args_dict, (network_params, actor_params, critic_params) = deserialized_data\n",
    "\n",
    "    network.params = network_params\n",
    "    actor.params = actor_params\n",
    "    critic.params = critic_params\n",
    "\n",
    "    return (network, actor, critic), args_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "440c6a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "#Load model in \n",
    "\n",
    "SEED=42\n",
    "ACTION_DIMENSION = 36\n",
    "OBS_SHAPE = (1, 4, 64, 64) # (batch, timesteps, x, y)\n",
    "\n",
    "network = Network()\n",
    "actor = Actor(action_dim=ACTION_DIMENSION)\n",
    "critic = Critic()\n",
    "\n",
    "key = jax.random.PRNGKey(SEED)\n",
    "\n",
    "key, network_key, actor_key, critic_key = jax.random.split(key, 4)\n",
    "sample_obs = np.zeros(OBS_SHAPE,dtype=np.float32)\n",
    "print(sample_obs.shape)\n",
    "network_params = network.init(network_key, sample_obs)\n",
    "actor_params = actor.init(actor_key, network.apply(network_params, sample_obs)[0])\n",
    "critic_params = critic.init(critic_key, network.apply(network_params, sample_obs)[0])\n",
    "\n",
    "with open(SAVED_MODEL_PATH, \"rb\") as f:\n",
    "    (args, (network_params, actor_params, critic_params)) = flax.serialization.from_bytes(\n",
    "        (None, (network_params, actor_params, critic_params)), f.read()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4823639",
   "metadata": {},
   "outputs": [],
   "source": [
    "#action/id mapping\n",
    "#Punching is enabled by default\n",
    "# mouse values are (x,y) pairs\n",
    "action_mapping = {\n",
    "    0:\"mouse -25 -25\",\n",
    "    1:\"mouse -25 0\",\n",
    "    2:\"mouse -25 25\",\n",
    "    3:\"mouse 0 -25\",\n",
    "    4:\"mouse 0 0\",#null op\n",
    "    5:\"mouse 0 25\",\n",
    "    6:\"mouse 25 -25\",\n",
    "    7:\"mouse 25 0\",\n",
    "    8:\"mouse 25 25\",\n",
    "    9:\"mouse -25 -25\",\n",
    "    10:\"mouse -25 0, JUMP\",\n",
    "    11:\"mouse -25 25, JUMP\",\n",
    "    12:\"mouse 0 -25, JUMP\",\n",
    "    13:\"mouse 0 0, JUMP\",\n",
    "    14:\"mouse 0 25, JUMP\",\n",
    "    15:\"mouse 25 -25, JUMP\",\n",
    "    16:\"mouse 25 0, JUMP\",\n",
    "    17:\"mouse 25 25, JUMP\",\n",
    "    18:\"mouse -25 -25, JUMP\",\n",
    "    19:\"mouse -25 0, FORWARD\",\n",
    "    20:\"mouse -25 25, FORWARD\",\n",
    "    21:\"mouse 0 -25, FORwARD\",\n",
    "    22:\"mouse 0 0, FORWARD\",\n",
    "    23:\"mouse 0 25, FORWARD\",\n",
    "    24:\"mouse 25 -25, FORWARD\",\n",
    "    25:\"mouse 25 0, FORWARD\",\n",
    "    26:\"mouse 25 25, FORWARD\",\n",
    "    27:\"mouse -25 -25, FORWARD, JUMP\",\n",
    "    28:\"mouse -25 0, FORWARD, JUMP\",\n",
    "    29:\"mouse -25 25, FORWARD, JUMP\",\n",
    "    30:\"mouse 0 -25, FORWARD, JUMP\",\n",
    "    31:\"mouse 0 0, FORWARD, JUMP\",\n",
    "    32:\"mouse 0 25, FORWARD, JUMP\",\n",
    "    33:\"mouse 25 -25 FORWARD, JUMP\",\n",
    "    34:\"mouse 25 0, FORWARD, JUMP\",\n",
    "    35:\"mouse 25 25, FOWARD, JUMP\",\n",
    "    \n",
    "}\n",
    "forward_mask = jnp.array([0]*18+[1]*18)\n",
    "jump_mask = jnp.array(([0]*9+[1]*9)*2)\n",
    "up_mask = jnp.array([1,0,0]*12)\n",
    "down_mask = jnp.array([0,0,1]*12)\n",
    "left_mask = jnp.array(([1]*3+[0]*6)*4)\n",
    "right_mask = jnp.array(([0]*6+[1]*3)*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98a79a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith((\".png\", \".jpg\", \".jpeg\")):  # add more image types if necessary\n",
    "            img = Image.open(os.path.join(folder, filename))\n",
    "            if img is not None:\n",
    "                img_arr = np.array(img)\n",
    "                images.append(img_arr)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00d03b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frames(frames):\n",
    "\n",
    "    # Create a figure with 4 subplots, one for each frame\n",
    "    fig, axs = plt.subplots(1, frames.shape[0], figsize=(12, 3))\n",
    "\n",
    "    # Loop through each frame and plot it on a separate subplot\n",
    "    for i in range(frames.shape[0]):\n",
    "        axs[i].imshow(frames[i], cmap='gray')\n",
    "        axs[i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15f6bc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    image = cv2.resize(\n",
    "            image, (64,64), interpolation=cv2.INTER_AREA\n",
    "        )\n",
    "    return image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e9d66b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load screen shots from folder\n",
    "images = load_images_from_folder(IMAGE_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d3bd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_gradient(output_fn, target=\"input\"):\n",
    "    if target == \"input\":\n",
    "        def f(x):\n",
    "            hidden, layers = network.apply(network_params, x)\n",
    "            action_logits = actor.apply(actor_params, hidden)\n",
    "            critic_values = critic.apply(critic_params, hidden)\n",
    "            output = output_fn(action_logits, critic_values, hidden, layers)\n",
    "            return output\n",
    "    if target == \"l1\":\n",
    "        def f(x):\n",
    "            hidden, layers = network.apply(network_params, None, l1_inp=True, inp=x)\n",
    "            action_logits = actor.apply(actor_params, hidden)\n",
    "            critic_values = critic.apply(critic_params, hidden)\n",
    "            output = output_fn(action_logits, critic_values, hidden, layers)\n",
    "            return output\n",
    "    if target == \"l2\":\n",
    "        def f(x):\n",
    "            hidden, layers = network.apply(network_params, None, l2_inp=True, inp=x)\n",
    "            action_logits = actor.apply(actor_params, hidden)\n",
    "            critic_values = critic.apply(critic_params, hidden)\n",
    "            output = output_fn(action_logits, critic_values, hidden, layers)\n",
    "            return output\n",
    "    if target == \"l3\":\n",
    "        def f(x):\n",
    "            hidden, layers = network.apply(network_params, None, l3_inp=True, inp=x)\n",
    "            action_logits = actor.apply(actor_params, hidden)\n",
    "            critic_values = critic.apply(critic_params, hidden)\n",
    "            output = output_fn(action_logits, critic_values, hidden, layers)\n",
    "            return output\n",
    "    if target == \"network\":\n",
    "        def f():\n",
    "            def f(x):\n",
    "                hidden, layers = x, (None,None,None)\n",
    "                action_logits = actor.apply(actor_params, hidden)\n",
    "                critic_values = critic.apply(critic_params, hidden)\n",
    "                output = output_fn(action_logits, critic_values, hidden, layers)\n",
    "            return output\n",
    "    return jax.value_and_grad(f)\n",
    "\n",
    "def deep_dream(init_input, output_fn, target=\"input\", lr=1e3, n_iter=600, clip_low=0, clip_high=255):\n",
    "    \n",
    "    hidden,layers = network.apply(network_params,init_input)\n",
    "    if target == \"input\":\n",
    "        x = init_input\n",
    "    if target == \"l1\":\n",
    "        x = layers[0]\n",
    "    if target == \"l2\":\n",
    "        x = layers[1]\n",
    "    if target == \"l3\":\n",
    "        x = layers[2]\n",
    "    if target == \"network\":\n",
    "        x = hidden\n",
    "    \n",
    "    f = jax.jit(network_gradient(output_fn, target=target))\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        value, grad = f(x)\n",
    "        x += lr*grad\n",
    "        x = jnp.clip(x, clip_low, clip_high)\n",
    "        if i % 200 == 0:\n",
    "            print(\"Iteration:\", i, \"Value\", value)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c21eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the yaw probablity as p(turn left)-p(turn right)\n",
    "\n",
    "def yaw_probabilty(action_logits, critic_output, network_output, layers, orientation):\n",
    "    if orientation == \"left\":\n",
    "        x = 1\n",
    "    if orientation == \"right\":\n",
    "        x = -1\n",
    "    action_ps = jax.vmap(jax.nn.softmax)(action_logits)\n",
    "    yaw_values = jax.vmap(lambda x: jnp.dot(left_mask,x)-jnp.dot(right_mask,x))(action_ps)\n",
    "    return x*yaw_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655729e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_raw_image(image):\n",
    "    plt.imshow(image)\n",
    "    plt.gca().axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "def plt_network_image(image, cmap='viridis'):\n",
    "    plt.imshow(transform_image(image), cmap=cmap)\n",
    "    plt.gca().axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "def plt_latent(image, channel, layer=\"network\",cmap='viridis', is_active=False):\n",
    "    a = jnp.stack([transform_image(image)]*4)[np.newaxis,...]\n",
    "    hidden, layers = network.apply(network_params,a)\n",
    "    if layer == \"l1\":\n",
    "        layer_data = layers[0][0,:,:,channel]\n",
    "    if layer == \"l2\":\n",
    "        layer_data = layers[1][0,:,:,channel]\n",
    "    if layer == \"l3\":\n",
    "        layer_data = layers[2][0,:,:,channel]\n",
    "    if layer == \"network\":\n",
    "        layer_data = hidden.reshape(16,32)\n",
    "    \n",
    "    if is_active:\n",
    "        plt.imshow(layer_data > 0, cmap=cmap)\n",
    "    else:\n",
    "        plt.imshow(layer_data, cmap=cmap)\n",
    "    plt.gca().axis('off')\n",
    "    plt.show()\n",
    "    print(\"min_val:\", jnp.min(layer_data), \"max_val:\", jnp.max(layer_data))\n",
    "    print(\"------------------------------\")\n",
    "    \n",
    "def plt_gradient(image, channel, output_fn, layer=\"network\",cmap='viridis'):\n",
    "    network_input = jnp.stack([transform_image(image)]*4)[np.newaxis,...]\n",
    "    hidden, layers = network.apply(network_params,network_input)\n",
    "    if layer == \"input\":\n",
    "        x = network_input\n",
    "    if layer == \"l1\":\n",
    "        x = layers[0]\n",
    "    if layer == \"l2\":\n",
    "        x = layers[1]\n",
    "    if layer == \"l3\":\n",
    "        x = layers[2]\n",
    "    if layer == \"network\":\n",
    "        x = hidden\n",
    "    \n",
    "    _,gradient = jax.jit(network_gradient(output_fn, target=layer))(x)\n",
    "    \n",
    "    if layer == \"network\":\n",
    "        gradient = gradient.reshape(1,16,32,1)\n",
    "    \n",
    "        \n",
    "    plt.imshow(gradient[0,:,:,channel], cmap=cmap)\n",
    "    plt.gca().axis('off')\n",
    "    plt.show()\n",
    "    print(\"min_val:\", jnp.min(gradient[0,:,:,channel]), \"max_val:\", jnp.max(gradient[0,:,:,channel]))\n",
    "    print(\"------------------------------\")\n",
    "    \n",
    "def print_actions(image):\n",
    "    a = jnp.stack([transform_image(image)]*4)[np.newaxis,...]\n",
    "    network_state, layers = network.apply(network_params,a)\n",
    "    action_logits = actor.apply(actor_params,network_state)\n",
    "    action_ps = jax.nn.softmax(action_logits)[0]\n",
    "    \n",
    "    yaw_value = jnp.dot(left_mask,action_ps)-jnp.dot(right_mask,action_ps)\n",
    "    pitch_value = jnp.dot(up_mask,action_ps)-jnp.dot(down_mask,action_ps)\n",
    "    jump_value = jnp.dot(jump_mask,action_ps)\n",
    "    forward_value = jnp.dot(forward_mask,action_ps)\n",
    "    \n",
    "    print(\"Yaw:\", yaw_value)\n",
    "    print(\"Pitch:\", pitch_value)\n",
    "    print(\"Forward:\", forward_value)\n",
    "    print(\"Jump:\", jump_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064deea0",
   "metadata": {},
   "source": [
    "## Interpreting the policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6609621f",
   "metadata": {},
   "source": [
    "### Deep Dreaming\n",
    "We can use the `deep_dream` function to probe the model for high value states and inputs that trigger particular actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e183e565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deep dreaming to find high value states\n",
    "\n",
    "frames = jnp.array(np.random.rand(1,4,64,64), dtype=jnp.float32)*0.1+128\n",
    "\n",
    "def get_critic(a,critic,c,d):\n",
    "    return critic[0][0]\n",
    "print(\"Mean brightness before optimization:\", jnp.mean(frames))\n",
    "optimized_frames = deep_dream(frames,get_critic,n_iter=500)\n",
    "plot_frames(optimized_frames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455c573a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deep dreaming to find high yaw states\n",
    "\n",
    "#Effects are clearly visible when we initialize from a roughly uniform value\n",
    "frames = jnp.array(np.random.rand(1,4,64,64))*0.1+128\n",
    "\n",
    "def f(frames):\n",
    "    last_frame = frames[-1] #The last frame is most salient\n",
    "    last_frame_squared = np.array((last_frame-np.mean(last_frame))**2)# Look at squared deviation\n",
    "    blurred_squared_last_frame = cv2.GaussianBlur(last_frame_squared,(5,5),0) #Apply smoothing\n",
    "    return blurred_squared_last_frame[np.newaxis,:,:]\n",
    "\n",
    "optimized_frames_left = deep_dream(frames,lambda a,b,c,d: yaw_probabilty(a,b,c,d,\"left\"))\n",
    "optimized_frames_right = deep_dream(frames,lambda a,b,c,d: yaw_probabilty(a,b,c,d,\"right\"))\n",
    "\n",
    "amplitude_left = f(optimized_frames_left[0])\n",
    "amplitude_right = f(optimized_frames_right[0])\n",
    "output = np.concatenate([amplitude_left, amplitude_right])\n",
    "\n",
    "plot_frames(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1236de",
   "metadata": {},
   "source": [
    "### Alignment between actor and critic\n",
    "\n",
    "We notice that the actor an critic pay attention to the same set of features more than one would expect if their values were random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040c32a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_matrix = actor_params[\"params\"][\"Dense_0\"][\"kernel\"]\n",
    "critic_vector = critic_params[\"params\"][\"Dense_0\"][\"kernel\"]\n",
    "similarity_scores = cosine_similarity(critic_vector.reshape(1, -1), actor_matrix.T)\n",
    "plt.hist(similarity_scores.reshape(-1))\n",
    "similarity_scores = cosine_similarity(np.random.randn(512).reshape(1, -1), actor_matrix.T)\n",
    "plt.hist(similarity_scores.reshape(-1))\n",
    "plt.legend(['Actor/Critic cosine similarity', 'Random cosine similarity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca874a5",
   "metadata": {},
   "source": [
    "### What the model sees vs what humans see\n",
    "\n",
    "The input image is downscaled from 600x1024x3 RGB -> 64x64 greyscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4737d66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 12\n",
    "image  = images[image_id]\n",
    "print(\"What humans see:\")\n",
    "plt_raw_image(image)\n",
    "print(\"What the network sees:\")\n",
    "plt_network_image(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b9d0bf",
   "metadata": {},
   "source": [
    "### The network's control system\n",
    "\n",
    "We can see for many images with trees in them, that by mirroring the image, the sign of the yaw probablity is inverted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfbf637",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 1\n",
    "image  = images[image_id]\n",
    "plt_network_image(image)\n",
    "print_actions(image)\n",
    "\n",
    "image  = images[image_id][:,::-1,:]\n",
    "plt_network_image(image)\n",
    "print_actions(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3057784b",
   "metadata": {},
   "source": [
    "### Generalization to the night\n",
    "\n",
    "We see that the control system seems to keep working with different tree types and even at night, where colors are inverted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426cc670",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 30\n",
    "image  = images[image_id]\n",
    "plt_network_image(image)\n",
    "print_actions(image)\n",
    "\n",
    "image  = images[image_id][:,::-1,:]\n",
    "plt_network_image(image)\n",
    "print_actions(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060df38f",
   "metadata": {},
   "source": [
    "### Drilling into Layer 1\n",
    "\n",
    "We can plot the activation for typical images to see how the internal activations react. Values above 0 will cause a relu network to pass the value forward. For instance, we can see channel 21 acting as a left/right edge detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77541a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id =1\n",
    "image = images[image_id]\n",
    "print(\"What the network sees:\")\n",
    "plt_network_image(image)\n",
    "\n",
    "print(\"Pre ReLU activation:\")\n",
    "plt_latent(np.array(image, dtype=np.float32),21,layer=\"l1\")\n",
    "print(\"Which ReLU's get triggered:\")\n",
    "plt_latent(np.array(image, dtype=np.float32),21,layer=\"l1\", is_active=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c9ad57",
   "metadata": {},
   "source": [
    "### Tree detectors in layers 2 and 3\n",
    "\n",
    "We found that channel 56 in layer 2 and channel 0 in layer 3 acted somewhat reliably as a tree detectors, even at night."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb1a439",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 15\n",
    "image = images[image_id]\n",
    "print(\"What the network sees:\")\n",
    "plt_network_image(image)\n",
    "\n",
    "print(\"Pre ReLU activation:\")\n",
    "plt_latent(np.array(image, dtype=np.float32),56,layer=\"l2\")\n",
    "print(\"Which ReLU's get triggered:\")\n",
    "plt_latent(np.array(image, dtype=np.float32),56,layer=\"l2\", is_active=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6f8149",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 15\n",
    "image = images[image_id]\n",
    "print(\"What the network sees:\")\n",
    "plt_network_image(image)\n",
    "\n",
    "print(\"Pre ReLU activation:\")\n",
    "plt_latent(np.array(image, dtype=np.float32),0,layer=\"l3\")\n",
    "print(\"Which ReLU's get triggered:\")\n",
    "plt_latent(np.array(image, dtype=np.float32),0,layer=\"l3\", is_active=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea58ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 12\n",
    "image  = images[image_id][:,::-1,:]\n",
    "print(\"What humans see:\")\n",
    "plt_raw_image(image)\n",
    "print(\"What the network sees:\")\n",
    "plt_network_image(image)\n",
    "print(\"Activations:\")\n",
    "plt_latent(image,0,layer=\"l3\")\n",
    "print(\"Gradient:\")\n",
    "plt_gradient(image,0, lambda a,b,c,d: yaw_probabilty(a,b,c,d,\"right\"),layer=\"l3\")\n",
    "print_actions(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
